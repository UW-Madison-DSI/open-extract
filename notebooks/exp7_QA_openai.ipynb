{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_extract.llm import QUESTIONS\n",
    "from open_extract.data_model import QA\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "model = \"o3-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(md_path: Path, question: str, client: openai.OpenAI, model: str) -> QA:\n",
    "    \"\"\"Extract Paper structure from text.\"\"\"\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a research assistant specializing in agriculture, your role is to extract data from academic papers and provide accurate answers based on their findings.\",\n",
    "    }\n",
    "    user_message= {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{md_path.read_text()} \\n\\n Answer this question based on the above information only: {question}\",\n",
    "    }\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[system_message, user_message],\n",
    "        response_format=QA,\n",
    "    )\n",
    "\n",
    "    if completion.choices[0].message.parsed is None:\n",
    "        raise ValueError(\"Failed to extract paper structure.\")\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(md_file: Path, questions: dict, client: openai.OpenAI, model: str) -> None:\n",
    "\n",
    "    run_path = Path(\"runs/openai_qa_250211\")\n",
    "    run_path.mkdir(exist_ok=True, parents=True)\n",
    "    output_file = run_path / f\"{md_file.stem}.jsonl\"\n",
    "\n",
    "    if output_file.exists():\n",
    "        return\n",
    "    \n",
    "    for question in questions.values():\n",
    "        try:\n",
    "            answer = extract(md_file, question, client, model)\n",
    "            with open(output_file, \"a\") as f:\n",
    "                f.write(answer.model_dump_json(indent=4) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  md_file in Path(\"data/prototype_250124/mds\").glob(\"*.md\"):\n",
    "    pipeline(md_file, QUESTIONS, client, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems better, especially in extracting: \n",
    "- study_is_answering_question\n",
    "- confidence\n",
    "\n",
    "The qualitative answer seems to be similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
